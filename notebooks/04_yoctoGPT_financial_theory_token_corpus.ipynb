{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tae-logo"
   },
   "source": [
    "<img src=\"https://theaiengineer.dev/tae_logo_gw_flatter.png\" width=\"35%\" align=\"right\">\n"
   ],
   "id": "tae-logo"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tae-header"
   },
   "source": [
    "# yoctoGPT â€” Finance Text Corpus (Token Mode)\n",
    "\n",
    "This notebook trains `yoctoGPT` on a **finance text corpus** from the `finance/` folder.\n",
    "It currently includes `financial_theory.txt`, and can scale to multiple finance `.txt` files later.\n",
    "Target setup: **Google Colab + L4 GPU**."
   ],
   "id": "tae-header"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "how-to-use"
   },
   "source": [
    "## How to Use This Notebook\n",
    "\n",
    "1. Run setup and ensure at least one `.txt` exists in `finance/`.\n",
    "2. Build tokenizer + dataset from all `finance/*.txt` files.\n",
    "3. Train with L4-friendly defaults.\n",
    "4. Sample and score text quality with readability metrics.\n",
    "5. Optionally resume from `best.pt` with a lower LR."
   ],
   "id": "how-to-use"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roadmap"
   },
   "source": [
    "### Roadmap\n",
    "- Setup and environment checks\n",
    "- Multi-file finance tokenization (`finance/*.txt`)\n",
    "- L4 training run\n",
    "- Sampling + readability scoring\n",
    "- Resume from best checkpoint"
   ],
   "id": "roadmap"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "#@title Mount Google Drive for checkpoint storage (repo stays local)\n",
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "CKPT_DIR = Path('/content/drive/MyDrive/yocto/checkpoints/financial_theory_token')\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Checkpoints dir:', CKPT_DIR)"
   ],
   "id": "mount-drive"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-code"
   },
   "outputs": [],
   "source": [
    "#@title Setup: Install Dependencies and Clone Repository\n",
    "!nvidia-smi || true\n",
    "!pip -q install tokenizers tqdm textstat\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import subprocess\n",
    "\n",
    "repo_root = pathlib.Path('/content/yoctoGPT')\n",
    "if repo_root.exists():\n",
    "    print('Repo exists, pulling latest...')\n",
    "    subprocess.run(['git', 'pull'], cwd=repo_root, check=False)\n",
    "else:\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/yhilpisch/yoctoGPT.git', str(repo_root)], check=False)\n",
    "os.chdir(repo_root)\n",
    "\n",
    "if os.path.exists('requirements.txt'):\n",
    "    !pip -q install -r requirements.txt || true\n",
    "\n",
    "finance_dir = pathlib.Path('finance')\n",
    "finance_dir.mkdir(exist_ok=True)\n",
    "txts = sorted(finance_dir.glob('*.txt'))\n",
    "if not txts:\n",
    "    raise FileNotFoundError('No .txt files found in finance/. Add at least one corpus file.')\n",
    "\n",
    "print(f'Found {len(txts)} finance text file(s):')\n",
    "for fp in txts[:10]:\n",
    "    print(' -', fp.name)\n",
    "if len(txts) > 10:\n",
    "    print(' - ...')"
   ],
   "id": "setup-code"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "token-intro"
   },
   "source": [
    "### Tokenization\n",
    "\n",
    "For technical finance text (formulas, symbols, and code-like fragments), token-level modeling is typically more effective than pure character-level modeling.\n",
    "\n",
    "We build one tokenizer from **all files in `finance/`**."
   ],
   "id": "token-intro"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "token-code"
   },
   "outputs": [],
   "source": [
    "#@title Prepare Token-level Dataset from finance/*.txt\n",
    "!python -m scripts.prepare_tokenizer \\\n",
    "--all_txt_in_dir \\\n",
    "--text_dir finance \\\n",
    "--out_dir data/token_finance \\\n",
    "--vocab_size 12000 \\\n",
    "--backend bpe \\\n",
    "--random_split \\\n",
    "--split_seed 1337 \\\n",
    "--add_bos_eos"
   ],
   "id": "token-code"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pick-hyperparams"
   },
   "outputs": [],
   "source": [
    "#@title Pick L4-friendly block_size/batch_size\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "train_path = Path('data/token_finance/train.bin')\n",
    "val_path = Path('data/token_finance/val.bin')\n",
    "train_tokens = int(np.fromfile(train_path, dtype=np.int32).shape[0])\n",
    "val_tokens = int(np.fromfile(val_path, dtype=np.int32).shape[0])\n",
    "min_tokens = min(train_tokens, val_tokens)\n",
    "\n",
    "block_candidates = [512, 384, 256, 192, 128, 96, 64, 48, 32, 24, 16]\n",
    "block_size = next((b for b in block_candidates if min_tokens > b + 2), max(8, min_tokens - 2))\n",
    "\n",
    "target_tokens = min(32768, max(2048, min_tokens))\n",
    "batch_size = max(1, min(128, target_tokens // block_size))\n",
    "\n",
    "print(f'Using block_size={block_size}, batch_size={batch_size}')"
   ],
   "id": "pick-hyperparams"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-intro"
   },
   "source": [
    "### Training\n",
    "\n",
    "L4-oriented baseline: `gpt_fast` + bf16 + cosine schedule.\n",
    "\n",
    "This should provide a good balance of speed and quality for one technical book corpus."
   ],
   "id": "training-intro"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-code"
   },
   "outputs": [],
   "source": [
    "#@title Train (gpt_fast) on Colab L4\n",
    "from pathlib import Path\n",
    "\n",
    "CKPT_DIR = Path('/content/drive/MyDrive/yocto/checkpoints/finance_token')\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "!python -m yoctoGPT.train \\\n",
    "--mode token \\\n",
    "--data_dir data/token_finance \\\n",
    "--tokenizer_path data/token_finance/tokenizer.json \\\n",
    "--ckpt_dir {CKPT_DIR} \\\n",
    "--model_type gpt_fast \\\n",
    "--device cuda \\\n",
    "--n_layer 6 --n_head 6 --n_embd 384 \\\n",
    "--block_size {block_size} --batch_size {batch_size} \\\n",
    "--dropout 0.12 --weight_decay 0.08 \\\n",
    "--tie_weights --label_smoothing 0.05 \\\n",
    "--amp --amp_dtype bf16 \\\n",
    "--auto_microbatch \\\n",
    "--eval_interval 250 --eval_iters 30 \\\n",
    "--cosine_lr --warmup_iters 200 \\\n",
    "--min_lr 1e-5 --lr 1.5e-4 \\\n",
    "--max_iters 3000 \\\n",
    "--ema --ema_decay 0.999"
   ],
   "id": "training-code"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sampling-intro"
   },
   "source": [
    "### Sampling and Resuming\n",
    "\n",
    "Sample from `best.pt` and score readability. Then optionally resume from `best.pt` with a lower LR."
   ],
   "id": "sampling-intro"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sampling-code"
   },
   "outputs": [],
   "source": [
    "#@title Sample Continuation\n",
    "output_token = !python -m yoctoGPT.sampler \\\n",
    "--mode token \\\n",
    "--ckpt {CKPT_DIR}/best.pt \\\n",
    "--tokenizer_path data/token_finance/tokenizer.json \\\n",
    "--prompt \"in financial theory, the principle of no arbitrage implies\" \\\n",
    "--max_new_tokens 150 \\\n",
    "--temperature 0.9 --top_k 30 --top_p 0.9\n",
    "\n",
    "generated_text_token = '\\n'.join(output_token)\n",
    "print(generated_text_token)"
   ],
   "id": "sampling-code"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "readability-intro-04"
   },
   "id": "readability-intro-04",
   "source": [
    "### Readability Assessment\n",
    "\n",
    "Use the same readability scoring as other notebooks for direct comparison of output quality."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "readability-code-04"
   },
   "id": "readability-code-04",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Analyze Generated Text Readability\n",
    "from textstat import textstat\n",
    "\n",
    "def readability_scores(text: str) -> dict:\n",
    "    return {\n",
    "        'Flesch Reading Ease': textstat.flesch_reading_ease(text),\n",
    "        'Flesch-Kincaid Grade': textstat.flesch_kincaid_grade(text),\n",
    "        'Dale-Chall Score': textstat.dale_chall_readability_score(text),\n",
    "        'Text Standard': textstat.text_standard(text, float_output=False),\n",
    "    }\n",
    "\n",
    "scores = readability_scores(generated_text_token)\n",
    "for metric, value in scores.items():\n",
    "    print(f'{metric:20}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "resume-code"
   },
   "outputs": [],
   "source": [
    "#@title Resume training from best.pt (lower LR + early stopping)\n",
    "best = CKPT_DIR / 'best.pt'\n",
    "if not best.exists():\n",
    "    print('No best.pt found; skipping resume cell.')\n",
    "else:\n",
    "    !python -m yoctoGPT.train \\\n",
    "      --mode token \\\n",
    "      --data_dir data/token_finance \\\n",
    "      --tokenizer_path data/token_finance/tokenizer.json \\\n",
    "      --ckpt_dir {CKPT_DIR} \\\n",
    "      --resume {best} \\\n",
    "      --model_type gpt_fast \\\n",
    "      --device cuda \\\n",
    "      --n_layer 6 --n_head 6 --n_embd 384 \\\n",
    "      --block_size {block_size} --batch_size {batch_size} \\\n",
    "      --dropout 0.12 \\\n",
    "      --tie_weights \\\n",
    "      --amp --amp_dtype bf16 \\\n",
    "      --auto_microbatch \\\n",
    "      --cosine_lr --warmup_iters 80 \\\n",
    "      --lr 8e-5 --max_iters 1200 \\\n",
    "      --eval_interval 250 --eval_iters 80 \\\n",
    "      --early_stopping_patience 3 \\\n",
    "      --early_stopping_min_delta 0.01"
   ],
   "id": "resume-code"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exercises"
   },
   "source": [
    "### Exercises\n",
    "\n",
    "1. **Code-Like Behavior**: Try prompts that start with Python syntax (e.g., `def black_scholes(`) and compare outputs across temperatures.\n",
    "2. **Context Length**: Compare `block_size=384` vs `512` for coherence around formulas and multi-line explanations.\n",
    "3. **Architecture Comparison**: Train a shorter run with `--model_type gpt_plus` and compare validation loss and sample quality."
   ],
   "id": "exercises"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tae-footer"
   },
   "source": [
    "<img src=\"https://theaiengineer.dev/tae_logo_gw_flatter.png\" width=\"35%\" align=\"right\">\n"
   ],
   "id": "tae-footer"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
